{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-TKxzrBbtk_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6czPko3hrmY"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = \"/content/drive/MyDrive/detection.zip\"\n",
        "extract_path = \"/content/dataset/detection\"\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3czeButKhq9Q"
      },
      "outputs": [],
      "source": [
        "detection_yaml = \"\"\"path: /content/dataset/detection\n",
        "train: images/train\n",
        "val: images/val\n",
        "test: images/test\n",
        "\n",
        "names:\n",
        "  0: \"license_plate\"\n",
        "\"\"\"\n",
        "\n",
        "# Write to a file\n",
        "with open(\"detection.yaml\", \"w\") as f:\n",
        "    f.write(detection_yaml)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWdZoWkDsEqh"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5vfEMKAsD5r"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load YOLOv11 model with pretrained weights\n",
        "model = YOLO(\"yolo11n.pt\")  # Load YOLOv11 with pretrained weights\n",
        "\n",
        "# Train the model\n",
        "model.train(\n",
        "    data=\"/content/detection.yaml\",   # Path to your dataset YAML file\n",
        "    epochs=300,                      # Number of training epochs\n",
        "    imgsz=640,                      # Image size (resize to 640*640)\n",
        "    batch=128,                       # Batch size\n",
        "    device=\"cuda\",                  # Use GPU for training\n",
        "    pretrained=True,                # Use pretrained weights for transfer learning\n",
        "    patience=50,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load YOLOv11 model with pretrained weights\n",
        "model = YOLO(\"/content/drive/MyDrive/detection.pt\")  # Load YOLOv11 with pretrained weights"
      ],
      "metadata": {
        "id": "tT73W-eoMv7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0_Qvus0IitN"
      },
      "outputs": [],
      "source": [
        "model.val(data='/content/detection.yaml', split='test')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export the model to ONNX format\n",
        "model.export(format=\"onnx\")  # creates 'yolo11n.onnx'\n",
        "\n",
        "# Load the exported ONNX model\n",
        "onnx_model = YOLO(\"/content/drive/MyDrive/detection.onnx\")\n",
        "\n",
        "# Run inference\n",
        "onnx_model.val(data='/content/detection.yaml', split='test')"
      ],
      "metadata": {
        "id": "d3n0OgbROU6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export the model to NCNN format\n",
        "model.export(format=\"ncnn\")  # creates '/yolo11n_ncnn_model'\n",
        "\n",
        "# Load the exported NCNN model\n",
        "ncnn_model = YOLO(\"/content/drive/MyDrive/detection_ncnn_model\")\n",
        "\n",
        "# Run inference\n",
        "ncnn_model.val(data='/content/detection.yaml', split='test')"
      ],
      "metadata": {
        "id": "DzaQBXeGS6dQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export the model to TensorRT format\n",
        "model.export(format=\"engine\")  # creates 'detection.engine'\n",
        "\n",
        "# Load the exported TensorTR model\n",
        "tensorrt_model = YOLO(\"/content/drive/MyDrive/detection.engine\")\n",
        "\n",
        "# Run inference\n",
        "tensorrt_model.val(data='/content/detection.yaml', split='test')"
      ],
      "metadata": {
        "id": "ps1l9ez7eF0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vavvlicdsTYn"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = \"/content/drive/MyDrive/ocr.zip\"\n",
        "extract_path = \"/content/dataset\"\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4L6G3U-yxAN"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/PaddlePaddle/PaddleOCR.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KH9HWuj94XVC"
      },
      "outputs": [],
      "source": [
        "!pip install paddlepaddle-gpu\n",
        "!pip install pyclipper\n",
        "!pip install lmdb\n",
        "!pip install rapidfuzz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_rec_train.tar"
      ],
      "metadata": {
        "id": "5x3OsexwHPMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf /content/en_PP-OCRv3_rec_train.tar && rm /content/en_PP-OCRv3_rec_train.tar"
      ],
      "metadata": {
        "id": "Jziy4WqWHTEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y30mJV9RTuNr"
      },
      "outputs": [],
      "source": [
        "characters = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ&'\n",
        "\n",
        "# Specify the output file path\n",
        "output_file = '/content/character_dict.txt'\n",
        "\n",
        "# Open the file in write mode\n",
        "with open(output_file, 'w') as file:\n",
        "    # Write each character on a new line\n",
        "    for char in characters:\n",
        "        file.write(char + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ocr_yaml = \"\"\"Global:\n",
        "  debug: false\n",
        "  use_gpu: true\n",
        "  epoch_num: 500\n",
        "  log_smooth_window: 20\n",
        "  print_batch_step: 10\n",
        "  save_model_dir: ./output/v3_en_mobile\n",
        "  save_epoch_step: 3\n",
        "  eval_batch_step: [0, 117]\n",
        "  cal_metric_during_train: true\n",
        "  pretrained_model:\n",
        "  checkpoints:\n",
        "  save_inference_dir:\n",
        "  use_visualdl: false\n",
        "  infer_img: doc/imgs_words/ch/word_1.jpg\n",
        "  character_dict_path: /content/character_dict.txt\n",
        "  max_text_length: &max_text_length 8\n",
        "  infer_mode: false\n",
        "  use_space_char: true\n",
        "  distributed: true\n",
        "  save_res_path: ./output/rec/predicts_ppocrv3_en.txt\n",
        "\n",
        "\n",
        "Optimizer:\n",
        "  name: Adam\n",
        "  beta1: 0.9\n",
        "  beta2: 0.999\n",
        "  lr:\n",
        "    name: Cosine\n",
        "    learning_rate: 0.0005\n",
        "    warmup_epoch: 10\n",
        "  regularizer:\n",
        "    name: L2\n",
        "    factor: 1.0e-03\n",
        "\n",
        "\n",
        "Architecture:\n",
        "  model_type: rec\n",
        "  algorithm: SVTR_LCNet\n",
        "  Transform:\n",
        "  Backbone:\n",
        "    name: MobileNetV1Enhance\n",
        "    scale: 0.5\n",
        "    last_conv_stride: [1, 2]\n",
        "    last_pool_type: avg\n",
        "  Neck:\n",
        "    name: SequenceEncoder\n",
        "    encoder_type: svtr\n",
        "    dims: 64\n",
        "    depth: 2\n",
        "    hidden_dims: 80\n",
        "    use_guide: False\n",
        "  Head:\n",
        "    name: CTCHead\n",
        "    fc_decay: 0.001\n",
        "Loss:\n",
        "  name: CTCLoss\n",
        "\n",
        "PostProcess:\n",
        "  name: CTCLabelDecode\n",
        "\n",
        "Metric:\n",
        "  name: RecMetric\n",
        "  main_indicator: acc\n",
        "  ignore_space: False\n",
        "\n",
        "Train:\n",
        "  dataset:\n",
        "    name: SimpleDataSet\n",
        "    data_dir: /content/dataset/ocr\n",
        "    ext_op_transform_idx: 1\n",
        "    label_file_list:\n",
        "    - /content/dataset/ocr/train_list.txt\n",
        "    transforms:\n",
        "    - DecodeImage:\n",
        "        img_mode: BGR\n",
        "        channel_first: false\n",
        "    - SVTRRecResizeImg:\n",
        "        image_shape: [3, 48, 320]\n",
        "    - RecConAug:\n",
        "        prob: 0.5\n",
        "        ext_data_num: 2\n",
        "        image_shape: [3, 48, 320]\n",
        "        max_text_length: *max_text_length\n",
        "    - CTCLabelEncode:\n",
        "    - KeepKeys:\n",
        "        keep_keys:\n",
        "        - image\n",
        "        - label\n",
        "        - length\n",
        "  loader:\n",
        "    shuffle: true\n",
        "    batch_size_per_card: 64\n",
        "    drop_last: true\n",
        "    num_workers: 4\n",
        "Eval:\n",
        "  dataset:\n",
        "    name: SimpleDataSet\n",
        "    data_dir: /content/dataset/ocr\n",
        "    label_file_list:\n",
        "    - /content/dataset/ocr/test_list.txt\n",
        "    transforms:\n",
        "    - DecodeImage:\n",
        "        img_mode: BGR\n",
        "        channel_first: false\n",
        "    - CTCLabelEncode:\n",
        "    - SVTRRecResizeImg:\n",
        "        image_shape: [3, 48, 320]\n",
        "    - KeepKeys:\n",
        "        keep_keys:\n",
        "        - image\n",
        "        - label\n",
        "        - length\n",
        "  loader:\n",
        "    shuffle: false\n",
        "    drop_last: false\n",
        "    batch_size_per_card: 128\n",
        "    num_workers: 4\n",
        "\"\"\"\n",
        "\n",
        "# Write to a file\n",
        "with open(\"ocr.yaml\", \"w\") as f:\n",
        "    f.write(ocr_yaml)"
      ],
      "metadata": {
        "id": "xCCXHwLcNJg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "go9O5BRD3nrQ"
      },
      "outputs": [],
      "source": [
        "!python3 /content/PaddleOCR/tools/train.py -c /content/ocr.yaml -o Global.pretrained_model=/content/en_PP-OCRv3_rec_train/best_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/PaddleOCR/tools/export_model.py -c /content/ocr.yaml -o Global.pretrained_model=/content/output/v3_en_mobile/best_accuracy Global.save_inference_dir=/content/ocr_model"
      ],
      "metadata": {
        "id": "I9qyEl5Ofo7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install paddleocr\n",
        "import os\n",
        "from paddleocr import PaddleOCR\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "ocr = PaddleOCR(\n",
        "    det_model_dir=None,\n",
        "    cls_model_dir=None,\n",
        "    rec_model_dir='/content/drive/MyDrive/ocr',\n",
        "    rec_algorithm='SVTR_LCNet',\n",
        "    rec_char_dict_path='/content/character_dict.txt',\n",
        "    use_angle_cls=True,\n",
        "    lang='en'\n",
        ")\n",
        "\n",
        "# Directories\n",
        "image_dir = '/content/dataset/ocr/test'\n",
        "\n",
        "true_labels = {}\n",
        "with open('/content/dataset/ocr/test_list.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        image_path, true_label = line.strip().split('\\t')\n",
        "        img_id = os.path.splitext(image_path.split('/')[-1])[0]\n",
        "        true_labels[img_id] = true_label\n",
        "\n",
        "total = len(true_labels)\n",
        "latency = 0\n",
        "\n",
        "# Open the output file in write mode\n",
        "with open('/content/ocr_res.txt', 'w') as f:\n",
        "    # Process each image\n",
        "    for image_name in os.listdir(image_dir):\n",
        "        if image_name.endswith(('.jpg', '.png')):\n",
        "            image_path = os.path.join(image_dir, image_name)\n",
        "\n",
        "            # Perform OCR\n",
        "            start_time = time.time()\n",
        "            result = ocr.ocr(image_path, cls=False, det=False)\n",
        "            end_time = time.time()\n",
        "            latency += (end_time - start_time)\n",
        "\n",
        "            if result:\n",
        "                # Extract recognized text and confidence score\n",
        "                recognized_text = ''.join([line[-1][0] for line in result])\n",
        "\n",
        "                # Write the result to the file\n",
        "                f.write(f\"{image_path}\\t{recognized_text}\\n\")\n",
        "\n",
        "num_correct = 0\n",
        "incorrect_samples = []\n",
        "\n",
        "with open('/content/ocr_res.txt', 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in lines:\n",
        "        line = line.split('\\t')\n",
        "        img_id = os.path.splitext(line[0].split('/')[-1])[0]\n",
        "        pred = \"\".join(ch.upper() for ch in line[1] if ch.isalnum())\n",
        "\n",
        "        if true_labels[img_id] == pred:\n",
        "            num_correct += 1\n",
        "        else:\n",
        "            incorrect_samples.append((line[0], pred, true_labels[img_id]))\n",
        "\n",
        "print('The final accuracy is %.2f%%' % ((num_correct / total) * 100))\n",
        "print(f'The average latency is {(latency / total) * 1000:.2f} ms')"
      ],
      "metadata": {
        "id": "F0LZuYgNwe_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = \"/content/drive/MyDrive/endtoend.zip\"\n",
        "extract_path = \"/content/dataset\"\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ],
      "metadata": {
        "id": "VH09frpZsPFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install paddleocr\n",
        "import os\n",
        "from paddleocr import PaddleOCR\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "ocr = PaddleOCR(\n",
        "    det_model_dir=None,\n",
        "    cls_model_dir=None,\n",
        "    rec_model_dir='/content/drive/MyDrive/ocr_model',\n",
        "    rec_algorithm='SVTR_LCNet',\n",
        "    rec_char_dict_path='/content/character_dict.txt',\n",
        "    use_angle_cls=True,\n",
        "    lang='en'\n",
        ")\n",
        "\n",
        "# Directories\n",
        "image_dir = '/content/dataset/endtoend/test'\n",
        "\n",
        "true_labels = {}\n",
        "with open('/content/dataset/endtoend/test_list.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        image_path, true_label = line.strip().split('\\t')\n",
        "        img_id = os.path.splitext(image_path.split('/')[-1])[0]\n",
        "        true_labels[img_id] = true_label\n",
        "\n",
        "total = len(true_labels)\n",
        "\n",
        "num_correct = 0\n",
        "false_positives = 0\n",
        "false_negatives = 0\n",
        "\n",
        "for img_name in os.listdir(image_dir):\n",
        "    if not img_name.lower().endswith(('.jpg', '.png')):\n",
        "        continue\n",
        "\n",
        "    img_id = os.path.splitext(img_name)[0]\n",
        "    img = cv2.imread(os.path.join(image_dir, img_name))\n",
        "    boxes = model(img)[0].boxes\n",
        "\n",
        "    found_tp = False\n",
        "    found_fp = False\n",
        "\n",
        "    # Try every detection box until the first valid‐length OCR\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "        crop = img[y1:y2, x1:x2]\n",
        "\n",
        "        # Shape check: skip if height >= width\n",
        "        if crop.shape[0] >= crop.shape[1]:\n",
        "            continue\n",
        "\n",
        "        # Run OCR\n",
        "        ocr_res = ocr.ocr(crop, cls=False, det=False) or []\n",
        "        if not ocr_res:\n",
        "            continue\n",
        "\n",
        "        # Build the text string and length check\n",
        "        text = ''.join([line[0][0] for line in ocr_res])\n",
        "        if not (2 <= len(text) <= 8):\n",
        "            continue\n",
        "\n",
        "        # We have a “valid” OCR—decide TP vs FP\n",
        "        if text == true_labels[img_id]:\n",
        "            num_correct    += 1\n",
        "            found_tp        = True\n",
        "        else:\n",
        "            false_positives += 1\n",
        "            found_fp        = True\n",
        "\n",
        "        break  # stop after first valid‐length OCR\n",
        "\n",
        "    # If we never got TP or FP, it’s a false negative\n",
        "    if not (found_tp or found_fp):\n",
        "        false_negatives += 1\n",
        "\n",
        "print(f\"Accuracy    : {num_correct/total*100:.2f}%\")\n",
        "print(f\"False neg.  : {false_negatives/total*100:.2f}%\")\n",
        "print(f\"False pos.  : {false_positives/total*100:.2f}%\")"
      ],
      "metadata": {
        "id": "5QPmvZfskhzz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}